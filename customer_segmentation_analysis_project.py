# -*- coding: utf-8 -*-
"""Customer Segmentation Analysis Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kMsuEHbwJTYYr4iD5TQZ5ew8hRNmqlSH
"""

import pandas as pd

# Load the dataset
file_path = '/content/bank_transactions.csv'  # Path to the uploaded dataset
df = pd.read_csv(file_path)

# Display the first few rows of the dataset
print(df.head())

# Summary statistics
print(df.describe())

# Check for missing values
print(df.isnull().sum())

# Drop rows with missing values
df.dropna(inplace=True)

# Remove duplicates if any
df.drop_duplicates(inplace=True)

# Display the cleaned data
print(df.head())

# Convert TransactionDate to datetime format if necessary
df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])

# Calculate total amount spent by each customer
customer_df = df.groupby('CustomerID').agg({
    'TransactionAmount (INR)': 'sum',    # Total amount spent
    'TransactionDate': 'count'     # Number of transactions
}).rename(columns={'TransactionDate': 'TransactionCount'})

# Display the first few rows of the aggregated data
print(customer_df.head())

from sklearn.preprocessing import StandardScaler

# Normalize the data
scaler = StandardScaler()
customer_df_normalized = scaler.fit_transform(customer_df)

# Convert back to a DataFrame for ease of use
customer_df_normalized = pd.DataFrame(customer_df_normalized, columns=customer_df.columns, index=customer_df.index)

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Determine the optimal number of clusters using the Elbow method
sse = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(customer_df_normalized)
    sse.append(kmeans.inertia_)

# Plot the SSE for each value of k
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), sse, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('SSE')
plt.title('Elbow Method')
plt.show()

# Choose the optimal number of clusters (e.g., 3) and fit the KMeans model
optimal_k = 3
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
customer_df['Cluster'] = kmeans.fit_predict(customer_df_normalized)

import seaborn as sns

# Analyze the characteristics of each cluster
cluster_summary = customer_df.groupby('Cluster').agg({
    'TransactionCount': 'mean',
    'TransactionAmount (INR)': 'mean'
}).reset_index()

print(cluster_summary)

# Visualize the segments
plt.figure(figsize=(10, 6))
sns.scatterplot(x='TransactionCount', y='TransactionAmount (INR)', hue='Cluster', data=customer_df, palette='viridis')
plt.title('Customer Segments')
plt.xlabel('Number of Transactions')
plt.ylabel('Total Amount Spent')
plt.show()

customer_df.to_csv('customer_segments.csv', index=False)

# Profile each segment
for cluster in customer_df['Cluster'].unique():
    print(f"Cluster {cluster} Profile:")
    print(customer_df[customer_df['Cluster'] == cluster].describe())
    print("\n")